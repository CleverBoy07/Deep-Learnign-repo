{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMoCl8T3XJ1J"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "df = pd.read_csv(\"/content/poems-100.csv\")\n",
        "df[\"text\"] = df[\"text\"].astype(str)\n",
        "\n",
        "text = \" \".join(df[\"text\"].values).lower()\n",
        "text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "words = text.split()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "word_counts = Counter(words)\n",
        "\n",
        "vocab = sorted(set(words))\n",
        "vocab.append(\"<UNK>\")\n",
        "\n",
        "word_to_idx = {w: i for i, w in enumerate(vocab)}\n",
        "idx_to_word = {i: w for w, i in word_to_idx.items()}\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "print(\"Vocabulary Size:\", vocab_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgZfjfHgXg9F",
        "outputId": "7e758207-a915-4b40-b2d0-532d16624653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size: 2211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = [word_to_idx.get(w, word_to_idx[\"<UNK>\"]) for w in words]\n",
        "\n",
        "sequence_length = 10\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for i in range(len(encoded) - sequence_length):\n",
        "    X.append(encoded[i:i+sequence_length])\n",
        "    y.append(encoded[i+sequence_length])\n",
        "\n",
        "import torch\n",
        "\n",
        "X = torch.tensor(X)\n",
        "y = torch.tensor(y)\n",
        "\n",
        "print(\"Dataset Shape:\", X.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cKhWj7SXi_s",
        "outputId": "45a138b0-2472-4c26-ae29-0ef6c4df1d79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Shape: torch.Size([7433, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class EmbeddingRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_size):\n",
        "        super(EmbeddingRNN, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "2ydY6PTYXlTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 100\n",
        "hidden_size = 128\n",
        "\n",
        "model = EmbeddingRNN(vocab_size, embed_dim, hidden_size)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n"
      ],
      "metadata": {
        "id": "V2rTdJuGXoFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "dataset = TensorDataset(X, y)\n",
        "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "epochs = 50\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch_x, batch_y in loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(batch_x)\n",
        "        loss = criterion(output, batch_y)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(loader):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLJ7-PkiXrEq",
        "outputId": "782c26ca-0bc5-4785-9ac1-f60b68547201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 6.6493\n",
            "Epoch 2, Loss: 5.9190\n",
            "Epoch 3, Loss: 5.3078\n",
            "Epoch 4, Loss: 4.4946\n",
            "Epoch 5, Loss: 3.5862\n",
            "Epoch 6, Loss: 2.7240\n",
            "Epoch 7, Loss: 1.9799\n",
            "Epoch 8, Loss: 1.4104\n",
            "Epoch 9, Loss: 0.9782\n",
            "Epoch 10, Loss: 0.6637\n",
            "Epoch 11, Loss: 0.4392\n",
            "Epoch 12, Loss: 0.2912\n",
            "Epoch 13, Loss: 0.1938\n",
            "Epoch 14, Loss: 0.1354\n",
            "Epoch 15, Loss: 0.0983\n",
            "Epoch 16, Loss: 0.0720\n",
            "Epoch 17, Loss: 0.0554\n",
            "Epoch 18, Loss: 0.0449\n",
            "Epoch 19, Loss: 0.0368\n",
            "Epoch 20, Loss: 0.0313\n",
            "Epoch 21, Loss: 0.0273\n",
            "Epoch 22, Loss: 0.0234\n",
            "Epoch 23, Loss: 0.0203\n",
            "Epoch 24, Loss: 0.0179\n",
            "Epoch 25, Loss: 0.0159\n",
            "Epoch 26, Loss: 0.0142\n",
            "Epoch 27, Loss: 0.0127\n",
            "Epoch 28, Loss: 0.0115\n",
            "Epoch 29, Loss: 0.0104\n",
            "Epoch 30, Loss: 0.0094\n",
            "Epoch 31, Loss: 0.0086\n",
            "Epoch 32, Loss: 0.0079\n",
            "Epoch 33, Loss: 0.0072\n",
            "Epoch 34, Loss: 0.0066\n",
            "Epoch 35, Loss: 0.0060\n",
            "Epoch 36, Loss: 0.0055\n",
            "Epoch 37, Loss: 0.0051\n",
            "Epoch 38, Loss: 0.0047\n",
            "Epoch 39, Loss: 0.0043\n",
            "Epoch 40, Loss: 0.0040\n",
            "Epoch 41, Loss: 0.0037\n",
            "Epoch 42, Loss: 0.0034\n",
            "Epoch 43, Loss: 0.0032\n",
            "Epoch 44, Loss: 0.0029\n",
            "Epoch 45, Loss: 0.0027\n",
            "Epoch 46, Loss: 0.0025\n",
            "Epoch 47, Loss: 0.0024\n",
            "Epoch 48, Loss: 0.0022\n",
            "Epoch 49, Loss: 0.0021\n",
            "Epoch 50, Loss: 0.0019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "def generate_text(start_text, length=30, temperature=0.8):\n",
        "    model.eval()\n",
        "\n",
        "    words_list = start_text.lower().split()\n",
        "    input_seq = [word_to_idx.get(w, word_to_idx[\"<UNK>\"]) for w in words_list]\n",
        "\n",
        "    for _ in range(length):\n",
        "\n",
        "        seq = input_seq[-sequence_length:]\n",
        "\n",
        "        if len(seq) < sequence_length:\n",
        "            seq = [0]*(sequence_length - len(seq)) + seq\n",
        "\n",
        "        x = torch.tensor([seq])\n",
        "\n",
        "        output = model(x)\n",
        "        output = output / temperature\n",
        "\n",
        "        probs = F.softmax(output, dim=1).detach().numpy().ravel()\n",
        "        predicted = np.random.choice(len(probs), p=probs)\n",
        "\n",
        "        words_list.append(idx_to_word[predicted])\n",
        "        input_seq.append(predicted)\n",
        "\n",
        "    return \" \".join(words_list)\n"
      ],
      "metadata": {
        "id": "4ltb1vDRXvdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(\"the moon\", 30, temperature=0.8))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1ZV1dwxX0UZ",
        "outputId": "ce91c56f-dac6-45cf-a175-a7715152d558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the moon ne of the fa here and the nor the negro of the wild gande yahonk he say the pert may s find its purpose the sharphoof chickadee th the litter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vI-ik42VZbj6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}