{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "votfY1RNsWfm",
        "outputId": "f3f34a9c-cb36-4b70-82cc-4c3408913575"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear dataset: (500, 2), classes: [-1  1]\n",
            "XOR dataset: (4, 2), classes: [0 1]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. LINEARLY SEPARABLE DATASET\n",
        "X_linear, y_linear = make_classification(\n",
        "    n_samples=500, n_features=2, n_informative=2, n_redundant=0,\n",
        "    n_clusters_per_class=1, class_sep=2.0, random_state=42\n",
        ")\n",
        "y_linear = 2 * y_linear - 1\n",
        "print(f\"Linear dataset: {X_linear.shape}, classes: {np.unique(y_linear)}\")\n",
        "\n",
        "X_xor = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
        "y_xor = np.array([0,1,1,0])\n",
        "print(f\"XOR dataset: {X_xor.shape}, classes: {np.unique(y_xor)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def perceptron_train(X, y, lr=0.01, epochs=1000):\n",
        "    \"\"\"Single-layer perceptron for linear separation\"\"\"\n",
        "    weights = np.random.randn(X.shape[1]) * 0.01\n",
        "    bias = 0\n",
        "    for epoch in range(epochs):\n",
        "        linear_out = X @ weights + bias\n",
        "        predictions = np.heaviside(linear_out, 1)\n",
        "\n",
        "        weights += lr * (y - predictions) @ X\n",
        "        bias += lr * np.mean(y - predictions)\n",
        "    return weights, bias\n",
        "\n",
        "def perceptron_predict(X, weights, bias):\n",
        "    linear_out = X @ weights + bias\n",
        "    return np.heaviside(linear_out, 1)\n",
        "\n",
        "\n",
        "w_lin, b_lin = perceptron_train(X_linear, y_linear)\n",
        "pred_lin = perceptron_predict(X_linear, w_lin, b_lin)\n",
        "acc_lin = np.mean(pred_lin == y_linear)\n",
        "print(f\"Linear dataset accuracy: {acc_lin:.1%}\")\n",
        "\n",
        "\n",
        "w_xor, b_xor = perceptron_train(X_xor, y_xor, epochs=5000, lr=0.1)\n",
        "pred_xor = perceptron_predict(X_xor, w_xor, b_xor)\n",
        "acc_xor = np.mean(pred_xor == y_xor)\n",
        "print(f\"XOR dataset accuracy: {acc_xor:.1%}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peXeup7MszUy",
        "outputId": "9ca4cc5f-9e50-45ad-e59c-f355e0283109"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear dataset accuracy: 47.4%\n",
            "XOR dataset accuracy: 50.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07b9613e",
        "outputId": "63f89b83-5726-40fd-ce02-2a4145ed366a"
      },
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-np.clip(z, -250, 250)))\n",
        "\n",
        "def relu(z):\n",
        "    return np.maximum(0, z)\n",
        "\n",
        "def relu_deriv(z):\n",
        "    return (z > 0).astype(float)\n",
        "\n",
        "class SimpleMLP:\n",
        "    def __init__(self, input_size=2, hidden_size=8, output_size=1):\n",
        "\n",
        "        self.W1 = np.random.randn(input_size, hidden_size) * 0.1\n",
        "        self.b1 = np.zeros((1, hidden_size))\n",
        "        self.W2 = np.random.randn(hidden_size, output_size) * 0.1\n",
        "        self.b2 = np.zeros((1, output_size))\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.z1 = X @ self.W1 + self.b1\n",
        "        self.a1 = relu(self.z1)\n",
        "        self.z2 = self.a1 @ self.W2 + self.b2\n",
        "        self.a2 = sigmoid(self.z2)\n",
        "        return self.a2\n",
        "\n",
        "    def backward(self, X, y_target, lr=1.0):\n",
        "        m = X.shape[0]\n",
        "\n",
        "\n",
        "        dz2 = self.a2 - y_target\n",
        "        dW2 = (1/m) * (self.a1.T @ dz2)\n",
        "        db2 = (1/m) * np.sum(dz2, axis=0, keepdims=True)\n",
        "\n",
        "\n",
        "        da1 = dz2 @ self.W2.T\n",
        "        dz1 = da1 * relu_deriv(self.z1)\n",
        "        dW1 = (1/m) * (X.T @ dz1)\n",
        "        db1 = (1/m) * np.sum(dz1, axis=0, keepdims=True)\n",
        "\n",
        "\n",
        "        self.W2 -= lr * dW2\n",
        "        self.b2 -= lr * db2\n",
        "        self.W1 -= lr * dW1\n",
        "        self.b1 -= lr * db1\n",
        "\n",
        "    def train(self, X, y, epochs=10000):\n",
        "        if y.ndim == 1:\n",
        "            y_reshaped = y.reshape(-1, 1)\n",
        "        else:\n",
        "            y_reshaped = y\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            self.forward(X)\n",
        "            self.backward(X, y_reshaped)\n",
        "            if epoch % 2000 == 0:\n",
        "                loss = np.mean((self.forward(X) - y_reshaped)**2)\n",
        "                print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        return (self.forward(X) > 0.5).astype(int).flatten()\n",
        "\n",
        "\n",
        "mlp_xor = SimpleMLP()\n",
        "mlp_xor.train(X_xor, y_xor)\n",
        "pred_xor_mlp = mlp_xor.predict(X_xor)\n",
        "acc_xor_mlp = np.mean(pred_xor_mlp == y_xor)\n",
        "print(f\"\\nXOR dataset accuracy: {acc_xor_mlp:.1%}\")\n",
        "\n",
        "y_linear_01 = (y_linear + 1) / 2\n",
        "mlp_lin = SimpleMLP()\n",
        "mlp_lin.train(X_linear, y_linear_01)\n",
        "pred_lin_mlp = mlp_lin.predict(X_linear)\n",
        "acc_lin_mlp = np.mean(pred_lin_mlp == y_linear_01)\n",
        "print(f\"Linear dataset accuracy: {acc_lin_mlp:.1%}\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.2487\n",
            "Epoch 2000, Loss: 0.0000\n",
            "Epoch 4000, Loss: 0.0000\n",
            "Epoch 6000, Loss: 0.0000\n",
            "Epoch 8000, Loss: 0.0000\n",
            "\n",
            "XOR dataset accuracy: 100.0%\n",
            "Epoch 0, Loss: 0.2377\n",
            "Epoch 2000, Loss: 0.0083\n",
            "Epoch 4000, Loss: 0.0031\n",
            "Epoch 6000, Loss: 0.0023\n",
            "Epoch 8000, Loss: 0.0021\n",
            "Linear dataset accuracy: 99.8%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ftJcEqPPs3i1"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}